{"path":"Extras/Images/Pasted image 20250110132031.png","text":"LIMtations witn 1€rrator 5 baCkenas Terraformy’s backends have a few limitations and gotchas that you need to be aware of. The first limitation is the chicken-and-egg situation of using Terraform to create the $3 bucket where you want to store your Terraform state. To make this work, you had to use a two-step process: 1. Write Terraform code to create the S3 bucket and DynamoDB table, and deploy that code with a local backend. 2. Go back to the Terraform code, add a remote backend configuration to it to use the newly created S3 bucket and DynamoDB table, and run terraform init to copy your local state to S3. If you ever wanted to delete the S3 bucket and DynamoDB table, youd have to do this two-step process in reverse: 1. Go to the Terraform code, remove the backend configuration, and rerun terraform init to copy the Terraform state back to your local disk. Limitations with Terraform’s Backends | 91 s 2. Run terraform destroy to delete the S3 bucket and DynamoDB table. This two-step process is a bit awkward, but the good news is that you can share a single S3 bucket and DynamoDB table across all of your Terraform code, so you'll probably only need to do it once (or once per AWS account if you have multiple accounts). After the S3 bucket exists, in the rest of your Terraform code, you can specify the backend configuration right from the start without any extra steps. The second limitation is more painful: the backend block in Terraform does not allow you to use any variables or references. The following code will not work: # This will NOT work. Variables aren't allowed in a backend configuration. terraform { backend \"s3\" { bucket = var.bucket region = var.region dynamodb_table = var.dynamodb_table key = \"example/terraform.tfstate\" encrypt = true } } This means that you need to manually copy and paste the S3 bucket name, region, DynamoDB table name, etc., into every one of your Terraform modules (you'll learn","libVersion":"0.5.0","langs":"eng"}